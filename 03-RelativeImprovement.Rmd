# Relative improvement

Our next, model deals with relative improvement of the algorithms over a baseline in noiseless functions. This model is based on a normal linear regression.

* **RQ2**   What is the expected improvement of these algorithms against the Random Search in noiseless benchmark functions in terms of approaching a global minima based in the Euclidean distance to the location of the closest global minima?  

## RQ2 Data preparation

We start importing the dataset

```{r ,message=F, warning=F}
dataset <- readr::read_csv('./data/statscomp.csv')
```

Let's select only the columns that interests us, in this case the Euclidean distance
```{r echo=T}
d<- dataset %>% 
    dplyr::select(Algorithm, CostFunction, SD, Budget=MaxFevalPerDimensions, simNumber, EuclideanDistance, OptimizationSuccessful) %>% 
    dplyr::filter(OptimizationSuccessful & SD==0) %>% 
    dplyr::select(-SD, -OptimizationSuccessful) 
```

Let's first make this a wide data set based on the algorithm to make it easier to compute the relative improvement over the Random Search. We are also dropping the RandomSearch2 since there is no noise in the benchmark functions

There are several ways that can be used to compute a relative improvement (and they will affect the result). The way we are using is to compare against the mean of distance of the 10 samples of the Random Search in each cost function for a specific budget. The way we are comparing is we divide the distance of each algorithm by the average distance of the random search. If this ratio is greater than 1 then random search is better, if smaller than 1 then the algorithm is better

```{r}
relativeImprovement <- function(x, rs){
  #x is the column
  #rs is the random search column
  ri <- (rs-x)/rs
  ri<-ifelse(ri < -1, -1, ri)
  ri<-ifelse(ri >  1,  1, ri)
  return(ri)
}

d_wide <- d %>% 
  tidyr::pivot_wider(
    names_from = Algorithm,
    values_from = EuclideanDistance) %>% 
  dplyr::select(-RandomSearch2) %>%
  dplyr::group_by(CostFunction, Budget) %>% 
  dplyr::mutate(avgRandomSearch=mean(RandomSearch1)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate_at(c("NelderMead", "PSO", "SimulatedAnnealing","CuckooSearch", "DifferentialEvolution", "CMAES"),
                   ~relativeImprovement(.x,rs=avgRandomSearch))
```

After we compute our metric we drop the Random Search column and we pivot_longer again to make the inference

```{r}
d_final <- d_wide %>% 
  dplyr::select(-RandomSearch1, -avgRandomSearch) %>% 
  tidyr::pivot_longer( 
    cols = c("NelderMead", "PSO", "SimulatedAnnealing","CuckooSearch", "DifferentialEvolution", "CMAES"),
    names_to = "Algorithm", 
    values_to = "y") %>% 
  dplyr::select(-simNumber) %>% 
  dplyr::mutate(AlgorithmID=create_index(Algorithm),
                CostFunctionID=create_index(CostFunction)) %>% 
  dplyr::select(Algorithm, AlgorithmID, CostFunction, CostFunctionID, Budget, y)

#checking if there is any na -> stan does not accept that 
find.na <- d_final %>% 
    dplyr::filter(is.na(y))

bm<-get_index_names_as_array(d_final$CostFunction)
saveRDS(bm, './data/relativeimprovement_bm.RDS')
algorithms <- get_index_names_as_array(d_final$Algorithm)
saveRDS(algorithms, './data/relativeimprovement_algorithms.RDS')
```

Now we have our final dataset to use with Stan. Lets preview a sample of the data set
```{r}
kable(dplyr::sample_n(d_final,size=10), "html",booktabs=T, format.args = list(scientific = FALSE), digits = 3) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) %>% 
  kableExtra::scroll_box(width = "100%")
```

```{r include=F}
saveRDS(dplyr::sample_n(d_final,size=4),'./statscomp-paper/tables/datafortables/relativeimprovementmodeldata.RDS')
```
 
## RQ2 Stan model

The Stan model is specified in the file: `'./stanmodels/relativeimprovement.stan'`. Note that at the end of the model we commented the generated quantities. This block generates the predictive posterior y_rep and the log likelihood, log_lik. These values are useful in diagnosing and validating the model but the end file is extremely large (~1Gb for 2000 iterations) and make many of the following calculations slow. If the reader wants to see these values is just to uncomment and run the stan model again

```{r}
print_stan_code('./stanmodels/relativeimprovement.stan')
```

Let's compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations `"./data/relativeimprovement-data.RDS"`

```{r}
standata <- list(
  N_total=nrow(d_final),
  y = d_final$y,
  N_algorithm = length(algorithms),
  algorithm_id = d_final$AlgorithmID,
  N_bm = length(bm),
  bm_id = d_final$CostFunctionID)
saveRDS(standata, file = "./data/relativeimprovement-data.RDS")
```

For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately
```{r echo=T, eval=F}
standata<-readRDS("./data/relativeimprovement-data.RDS")
relativeimprovement.fit <- stan(file = './stanmodels/relativeimprovement.stan',
                     data=standata,
                     chains = 4,
                     warmup = 200,
                     iter = 2000)
saveRDS(relativeimprovement.fit, file = "./data/relativeimprovement-fit.RDS")
```


```{r echo=F, include=F, eval=T}
relativeimprovement.fit <-readRDS("./data/relativeimprovement-fit.RDS")
```


## RQ2 Diagnosis

```{r}
a_alg <- c("a_alg[1]",
           "a_alg[2]",
           "a_alg[3]",
           "a_alg[4]",
           "a_alg[5]",
           "a_alg[6]")
rstan::traceplot(relativeimprovement.fit, pars=a_alg)
rstan::traceplot(relativeimprovement.fit, pars=c('s','sigma'))
```

Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling.
```{r}
kable(summary(relativeimprovement.fit)$summary) %>% 
  kable_styling(bootstrap_options = c('striped',"hover", "condensed" )) %>% 
  kableExtra::scroll_box(width = "100%")
```

## RQ2 Results and Plots

First lets get the HPDI of every parameter. 

Then we restrict to the algorithms, them to the slopes, then to the
```{r}
hpdi <- get_HPDI_from_stanfit(relativeimprovement.fit)

hpdi_algorithm <- hpdi %>% 
      dplyr::filter(str_detect(Parameter, "a_alg\\[")) %>%
      dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels

hpdi_other_parameters <- hpdi %>% 
      dplyr::filter(Parameter=='s' | Parameter=='sigma')


p_alg<-ggplot(data=hpdi_algorithm, aes(x=Parameter))+
  geom_pointrange(aes(
    ymin=HPDI.lower, 
    ymax=HPDI.higher, 
    y=Mean))+
  labs(y="Estimate of intercept", x="Algorithm")+
  coord_flip()
p_alg + plot_annotation(title = 'HPDI interval for the algorithms')

p_others <- ggplot(data=hpdi_other_parameters, aes(x=Parameter))+
  geom_pointrange(aes(
    ymin=HPDI.lower, 
    ymax=HPDI.higher, 
    y=Mean))+
  labs(y="Estimate of s and sigma", x="Parameter")+
  coord_flip()
p_others + plot_annotation(title = 'HPDI interval')
```

```{r echo=F, include=F, eval=T}
#figure for the paper
p<- (p_alg / p_others) + plot_annotation(title = 'HPDI interval of the parameters')
save_fig(p, 'relativeimprovement.pdf', type = 'single-column')
```


Creating an output table
```{r}
rename_pars <- c('sigma',paste(rep('a_',length(algorithms)), algorithms, sep = ""),'s')
t<-create_table_model(relativeimprovement.fit, c(a_alg, 's', 'sigma'), rename_pars)
colnames(t)<-c("Parameter", "Mean", "HPD low", "HPD high")
saveRDS(t,'./statscomp-paper/tables/datafortables/relativeimprovement-par-table.RDS')
```

```{r}
kable(t) %>% 
  kableExtra::scroll_box(width = "100%")
```


