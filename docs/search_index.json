[
["index.html", "Online Appendix for: Statistical Models for the Analysis of Optimization Algorithms with Benchmark Functions Preface Pre-requisites Source code Compiling this document Software environment", " Online Appendix for: Statistical Models for the Analysis of Optimization Algorithms with Benchmark Functions David Issa Mattos, Jan Bosch, Helena Holmström Olsson 26 June, 2020 Preface This document is an online appendix to the paper “Statistical Models for Benchmark Comparison” by David Issa Mattos, Jan Bosch and Helena Holmström Olsson. It shows the process to analyze the data, including data preparation, modeling and plotting for all the models described on the paper. Pre-requisites We assume that the reader has some familiarity with the R environment including packages included of the tidyverse, such as dplyr and ggplot2. The code presented is described and fairly commented to help readers follow the modeling process. Other programming languages such as Python with numpy, pandas, matplotlib etc are capable of performing the same steps, but this is out of the scope of this document. For the Bayesian models, we try to minimize dependency on a specific R package such as brms or rstanarm, and therefore we discuss the model in Stan only, since it has bindings for multiple programming languages. Source code The full source code is available in the repository. The raw data for each model (after the described data transformation) is also available for download in the ./data folder. The Stan models are available in the ./stanmodels folder. The utils folder contains some helper functions to help plotting, and generating figures etc… In the chapter utils we discuss each function in detail The environment was defined and based on the renv package. The renv package logs all the packages in the renv.lock file and manages installation for a specific project. For more information see !!!!!!! To replicate this environment, after downloading this repository, type: renv::hydrate() This command will download and install all the the packages use in this work. Note that it will install the packages only for this project. Compiling this document This document was created with the bookdown package. To compile it (and run every command to generate the models, figures and etc. ) type: rmarkdown::render_site(&#39;./index.Rmd&#39;, encoding = &#39;UTF-8&#39;); Software environment We suggest to use Stan installed in Linux. There appear to be several problems with Stan in Mac Os Catalina. The environment used is defined in the renv.lock file and session information used to compile this document is sessionInfo() R version 3.6.3 (2020-02-29) Platform: x86_64-apple-darwin15.6.0 (64-bit) Running under: macOS Catalina 10.15.4 Matrix products: default BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 attached base packages: [1] graphics grDevices datasets stats utils methods base other attached packages: [1] gtools_3.8.2 progress_1.2.2 ggthemr_1.1.0 viridis_0.5.1 [5] viridisLite_0.3.0 patchwork_1.0.0 coda_0.19-3 rstan_2.19.3 [9] StanHeaders_2.21.0-5 glue_1.4.1 forcats_0.5.0 stringr_1.4.0 [13] dplyr_1.0.0 purrr_0.3.4 readr_1.3.1 tidyr_1.1.0 [17] tibble_3.0.1 ggplot2_3.3.1 tidyverse_1.3.0 kableExtra_1.1.0 [21] rmdformats_0.3.7 knitr_1.28 loaded via a namespace (and not attached): [1] nlme_3.1-148 matrixStats_0.56.0 fs_1.4.1 lubridate_1.7.9 [5] webshot_0.5.2 httr_1.4.1 tools_3.6.3 backports_1.1.7 [9] utf8_1.1.4 R6_2.4.1 DBI_1.1.0 colorspace_1.4-1 [13] withr_2.2.0 tidyselect_1.1.0 gridExtra_2.3 prettyunits_1.1.1 [17] processx_3.4.2 compiler_3.6.3 cli_2.0.2 rvest_0.3.5 [21] formatR_1.7 HDInterval_0.2.2 xml2_1.3.2 labeling_0.3 [25] bookdown_0.19 scales_1.1.1 callr_3.4.3 digest_0.6.25 [29] rmarkdown_2.2 base64enc_0.1-3 pkgconfig_2.0.3 htmltools_0.4.0 [33] highr_0.8 dbplyr_1.4.4 rlang_0.4.6 readxl_1.3.1 [37] rstudioapi_0.11 farver_2.0.3 generics_0.0.2 jsonlite_1.6.1 [41] inline_0.3.15 magrittr_1.5 loo_2.2.0 Rcpp_1.0.4.6 [45] munsell_0.5.0 fansi_0.4.1 lifecycle_0.2.0 stringi_1.4.6 [49] yaml_2.2.1 pkgbuild_1.0.8 plyr_1.8.6 grid_3.6.3 [53] blob_1.2.1 parallel_3.6.3 crayon_1.3.4 lattice_0.20-41 [57] haven_2.3.1 hms_0.5.3 ps_1.3.3 pillar_1.4.4 [61] stats4_3.6.3 reprex_0.3.0 evaluate_0.14 renv_0.10.0 [65] RcppParallel_5.0.1 modelr_0.1.8 vctrs_0.3.1 cellranger_1.1.0 [69] gtable_0.3.0 assertthat_0.2.1 xfun_0.14 broom_0.5.6 [73] ellipsis_0.3.1 "],
["introduction.html", "Chapter 1 Introduction 1.1 The simulation", " Chapter 1 Introduction This document is based on a single dataset. We will ask several possible research questions from this dataset in order to develop and motivate the statistical models of this paper. But first let’s explore the dataset and how this data was obtained. 1.1 The simulation 1.1.1 Exploring the dataset This dataset follows the principle of tidy data as described in https://r4ds.had.co.nz/tidy-data.html. The key idea is that every variables has its own column, and every observation has its own unique row. Throughout this document, to facilitate our modeling approach, we will modify this dataset in different ways, often resulting in non-tidy data. However every model will start from the same base tidy dataset. This approach will hopefully make it easier for the reader to understand from where we are starting and adopt similar strategies in their own models. Additionally, we recommend, if the reader has the opportunity to influence the data collection process, the choice of tidy data. It is often ideal for exploratory analysis, plotting, is the basis for most models, and easy to transform to be used in different models. d &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) Here we are excluding a few columns to simplify our view kable(head(dplyr::select(d, -BestArm, -Continuous, -Differentiability, -Separability, -Scalability, -Modality,-BBOB,-BaseClass, -MaxFeval, -FevalPerDimensions), n=10)) Algorithm CostFunction NumberFunctionEval EuclideanDistance TrueRewardDifference CumulativeRegret TimeToComplete Ndimensions OptimizationSuccessful SD MaxFevalPerDimensions SolveAt1 SolveAt1e-1 SolveAt1e-3 SolveAt1e-6 SolveEarlierAt1 SolveEarlierAt1e-1 SolveEarlierAt1e-3 SolveEarlierAt1e-6 simNumber NelderMead BentCigarN6 600 8.9123708 7.364249e+07 4.926652e+10 0.0300207 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 PSO BentCigarN6 600 0.5605997 1.559497e+05 7.938082e+10 0.0394440 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 SimulatedAnnealing BentCigarN6 600 9.7499527 1.086834e+08 1.208830e+12 0.0424774 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 CuckooSearch BentCigarN6 600 8.0025211 1.200314e+07 1.017438e+13 0.0317579 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 DifferentialEvolution BentCigarN6 600 5.3888603 4.634518e+06 2.399718e+12 0.1168543 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 RandomSearch1 BentCigarN6 600 1.5702536 1.919896e+06 1.983989e+13 0.0399160 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 RandomSearch2 BentCigarN6 599 1.5702536 1.655484e+06 1.929796e+13 0.0356977 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 0 CMAES BentCigarN6 604 0.5744144 3.357865e-01 2.589247e+08 0.1810286 6 TRUE 0 100 TRUE FALSE FALSE FALSE 543 NA NA NA 0 NelderMead BentCigarN6 600 7.9123493 2.152945e+07 2.041479e+11 0.0423668 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 1 PSO BentCigarN6 600 1.0818350 1.853063e+05 7.224343e+10 0.0397996 6 TRUE 0 100 FALSE FALSE FALSE FALSE NA NA NA NA 1 1.1.2 Column definitions "],
["probability-of-success-model.html", "Chapter 2 Probability of success model 2.1 Data preparation 2.2 Stan model 2.3 Diagnosis 2.4 Results and Plots", " Chapter 2 Probability of success model Our first model can be used to address problems such as: RQ1 What is the probability of each solving a problem at precision \\(\\epsilon=0.1\\)? RQ2 What is the impact of noise in the probability of success of each algorithm? 2.1 Data preparation We start importing the dataset dataset &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) Let’s select only the columns that interests us. Note that some of the columns have \"\" because of the “-” in the column name dataset&lt;-select(dataset, Algorithm, CostFunction, SD, MaxFevalPerDimensions, simNumber, SolveAt1, &quot;SolveAt1e-1&quot;,&quot;SolveAt1e-3&quot;,&quot;SolveAt1e-6&quot;, OptimizationSuccessful) Let’s do some basic transformation 1 - We select only the cases where the optimization completed 2 - We convert True to 1 and 0 to false 3 - We group by the algorithms, functions, SD, and budget so we can summarize and create aggregated data 4 - We create an index of each algorithm and the cost functions. This is basically creating a map of NelderMead=1, PSO=2 etc… This makes things easier to work in Stan. For that we use the function create_index from the utils.R file 5 - We drop the columns we wont use 6 - Get an array with the names of the benchmark functions and the algorithms (to create nicer plots later with lengend) Since we are only looking at 1e-1 for the precision we comment the other lines d &lt;- dataset %&gt;% dplyr::filter(OptimizationSuccessful==TRUE) %&gt;% dplyr::mutate( solvedAt1e1=as.integer(dataset$&quot;SolveAt1e-1&quot;), budget=MaxFevalPerDimensions) %&gt;% dplyr::group_by(Algorithm, CostFunction, SD, budget) %&gt;% dplyr::summarize( solvedAt1e1=sum(solvedAt1e1), N=n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(AlgorithmID=create_index(Algorithm), CostFunctionID=create_index(CostFunction)) %&gt;% dplyr::select(Algorithm,AlgorithmID, CostFunction, CostFunctionID, SD, budget, N, y=solvedAt1e1, ) #List of algorithms bm &lt;- get_index_names_as_array(d$CostFunction) algorithms &lt;- get_index_names_as_array(d$Algorithm) Lets preview a sample of the data set kable(dplyr::sample_n(d,size=10),&quot;html&quot;, booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm AlgorithmID CostFunction CostFunctionID SD budget N y RandomSearch2 7 Damavandi 5 0 1000 10 1 NelderMead 4 BentCigarN6 1 0 1000 10 0 SimulatedAnnealing 8 ChenV 3 0 10000 10 0 CMAES 1 Tripod 27 0 1000 10 0 DifferentialEvolution 3 BentCigarN6 1 3 20 10 0 CuckooSearch 2 Mishra7N6 10 3 100 10 0 CuckooSearch 2 SalomonN2 15 0 1000 10 0 RandomSearch2 7 LunacekBiRastriginN6 9 0 10000 10 0 RandomSearch1 6 ChenV 3 0 100 10 0 PSO 5 SphereN6 22 3 1000 10 8 2.2 Stan model The Stan model is specified in the file: './stanmodels/probsuccess.stan' print_stan_code(&#39;./stanmodels/probsuccess.stan&#39;) // Probability of success model // Author: David Issa Mattos // Date: 16 June 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size int y[N_total]; // Result of the binomial int N_draw[N_total]; // Number of draws in the binomial real x_noise[N_total];//predictor for noise //To model each algorithm independently int &lt;lower=1&gt; N_algorithm; // Number of algorithms int algorithm_id[N_total]; //vector that has the id of each algorithm //To model the influence of each benchmark int &lt;lower=1&gt; N_bm; int bm_id[N_total]; } parameters { //Fixed effect real a_alg[N_algorithm];//the mean effect given by the algorithms real b_noise[N_algorithm];//slope for the noise // //Random effect. The effect of the benchmarks real a_bm_norm[N_bm];//the mean effect given by the base class type real&lt;lower=0&gt; s;//std for the random effects } model { real p[N_total]; //Fixed effect a_alg ~ normal(0,5); b_noise ~ normal(0,5); // //Random effects s ~ exponential(0.1); a_bm_norm ~ normal(0,2); for (i in 1:N_total) { p[i] = a_alg[algorithm_id[i]]+ a_bm_norm[bm_id[i]]*s + b_noise[algorithm_id[i]] * x_noise[i]; } //Equivalent to: y~binomial(N, inverse_logit(a+bx=alpha)) y ~ binomial_logit(N_draw,p); } Let’s compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations \"./data/probsuccsess-data.RDS\" standata &lt;- list( N_total = nrow(d), y = d$y, N_draw = d$N, x_noise = d$SD, N_algorithm = length(algorithms), algorithm_id =d$AlgorithmID, N_bm = length(bm), bm_id = d$CostFunctionID) saveRDS(standata, file = &quot;./data/probsuccsess-data.RDS&quot;) For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately standata&lt;-readRDS(&quot;./data/probsuccsess-data.RDS&quot;) probsuccess.fit &lt;- stan(file = &#39;./stanmodels/probsuccess.stan&#39;, data=standata, chains = 4, warmup = 200, iter = 3000) saveRDS(probsuccess.fit, file = &quot;./data/probsuccsess-fit.RDS&quot;) 2.3 Diagnosis The first step is to evaluate the convergence of the chains. We will look now only for the slopes, algorithms intercept and the standard deviation of the random effects a_alg &lt;- c(&quot;a_alg[1]&quot;, &quot;a_alg[2]&quot;, &quot;a_alg[3]&quot;, &quot;a_alg[4]&quot;, &quot;a_alg[5]&quot;, &quot;a_alg[6]&quot;, &quot;a_alg[7]&quot;, &quot;a_alg[8]&quot;) b_noise &lt;- c(&quot;b_noise[1]&quot;, &quot;b_noise[2]&quot;, &quot;b_noise[3]&quot;, &quot;b_noise[4]&quot;, &quot;b_noise[5]&quot;, &quot;b_noise[6]&quot;, &quot;b_noise[7]&quot;, &quot;b_noise[8]&quot;) rstan::traceplot(probsuccess.fit, pars=a_alg) rstan::traceplot(probsuccess.fit, pars=b_noise) rstan::traceplot(probsuccess.fit, pars=c(&#39;s&#39;)) Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling. kable(summary(probsuccess.fit)$summary) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat a_alg[1] -0.1020451 0.0200138 0.4384960 -0.9769125 -0.3958193 -0.0925058 0.1914637 0.7501188 480.0351 1.0105937 a_alg[2] -2.5550347 0.0202562 0.4442856 -3.4372204 -2.8538897 -2.5509935 -2.2537698 -1.6914831 481.0724 1.0105745 a_alg[3] -0.2152383 0.0201279 0.4383150 -1.0911027 -0.5093129 -0.2070574 0.0793034 0.6429023 474.2172 1.0110577 a_alg[4] -4.3540663 0.0200386 0.4551260 -5.2377436 -4.6609185 -4.3487623 -4.0432051 -3.4755955 515.8578 1.0105743 a_alg[5] -0.3969016 0.0200004 0.4399418 -1.2732582 -0.6929197 -0.3884974 -0.1096970 0.4660253 483.8531 1.0107383 a_alg[6] -2.0082860 0.0202404 0.4405144 -2.8806535 -2.3058513 -1.9977222 -1.7113927 -1.1544719 473.6744 1.0107742 a_alg[7] -2.2181415 0.0200633 0.4420479 -3.0992737 -2.5165273 -2.2085776 -1.9241674 -1.3536272 485.4365 1.0106134 a_alg[8] -2.5631023 0.0200175 0.4430360 -3.4403268 -2.8667111 -2.5550423 -2.2661899 -1.7064230 489.8440 1.0102213 b_noise[1] -1.2730843 0.0004939 0.0479101 -1.3683755 -1.3046373 -1.2732159 -1.2409493 -1.1793661 9410.8043 0.9999822 b_noise[2] -0.8114315 0.0006453 0.0598898 -0.9299608 -0.8507863 -0.8112586 -0.7713172 -0.6935132 8612.8888 1.0001499 b_noise[3] -1.3535279 0.0005371 0.0498852 -1.4539467 -1.3870825 -1.3527255 -1.3200302 -1.2572835 8627.4512 1.0000773 b_noise[4] -0.3844291 0.0007206 0.0709453 -0.5244092 -0.4317323 -0.3832629 -0.3369293 -0.2495743 9693.5893 1.0000912 b_noise[5] -1.1480142 0.0004772 0.0469081 -1.2412766 -1.1790465 -1.1480212 -1.1167563 -1.0565246 9664.0191 1.0001955 b_noise[6] -0.9645564 0.0005880 0.0577547 -1.0781541 -1.0026420 -0.9637580 -0.9260785 -0.8533345 9647.1139 0.9997367 b_noise[7] -0.7228396 0.0005845 0.0535182 -0.8267781 -0.7590856 -0.7230131 -0.6865815 -0.6171514 8384.2534 1.0000273 b_noise[8] -0.7951818 0.0005632 0.0588986 -0.9121320 -0.8344251 -0.7946279 -0.7558661 -0.6793954 10936.7629 0.9998205 a_bm_norm[1] -1.1075005 0.0166391 0.4172913 -1.9376944 -1.3940350 -1.1035309 -0.8158383 -0.3025256 628.9514 1.0076188 a_bm_norm[2] -2.7831547 0.0180702 0.6186835 -4.0816795 -3.1713042 -2.7555104 -2.3545626 -1.6555741 1172.2315 1.0034491 a_bm_norm[3] -1.2329340 0.0169342 0.4254943 -2.0764694 -1.5258060 -1.2288824 -0.9405891 -0.4166755 631.3328 1.0067100 a_bm_norm[4] 1.4034168 0.0175292 0.4121037 0.6089125 1.1186352 1.4003274 1.6891191 2.2121403 552.6972 1.0084829 a_bm_norm[5] -1.8436231 0.0172671 0.4847621 -2.8233063 -2.1690144 -1.8327380 -1.5085098 -0.9320440 788.1633 1.0054179 a_bm_norm[6] -0.2551456 0.0166820 0.3754357 -0.9846147 -0.5104907 -0.2592549 -0.0014329 0.4801150 506.4957 1.0099106 a_bm_norm[7] 4.1985668 0.0233068 0.6797093 2.9113872 3.7283821 4.1876559 4.6447582 5.5865641 850.5136 1.0046647 a_bm_norm[8] 2.8421307 0.0199401 0.5326900 1.8359073 2.4711306 2.8356333 3.1984079 3.9130317 713.6653 1.0059251 a_bm_norm[9] -4.5844754 0.0187770 1.0035687 -6.7848235 -5.2020631 -4.5067031 -3.8743225 -2.8638855 2856.5636 1.0012980 a_bm_norm[10] 0.0748274 0.0166087 0.3723473 -0.6462788 -0.1809241 0.0647216 0.3315689 0.8013401 502.6016 1.0098784 a_bm_norm[11] -0.9413159 0.0166869 0.4043907 -1.7360779 -1.2201570 -0.9411475 -0.6641474 -0.1646260 587.2895 1.0083764 a_bm_norm[12] 1.9464165 0.0183572 0.4515486 1.0964727 1.6328728 1.9392351 2.2562604 2.8303482 605.0552 1.0078365 a_bm_norm[13] 0.2250917 0.0168122 0.3704661 -0.4904174 -0.0245854 0.2158680 0.4805965 0.9545181 485.5653 1.0098796 a_bm_norm[14] -0.8403595 0.0165016 0.3968701 -1.6205628 -1.1093710 -0.8397354 -0.5671389 -0.0628831 578.4243 1.0085330 a_bm_norm[15] -0.4267101 0.0164941 0.3791410 -1.1587075 -0.6858467 -0.4290761 -0.1676661 0.3049254 528.3748 1.0095449 a_bm_norm[16] 0.1182341 0.0165257 0.3718541 -0.6007717 -0.1353910 0.1090619 0.3746432 0.8570316 506.3208 1.0094194 a_bm_norm[17] -0.1904070 0.0166915 0.3755492 -0.9074087 -0.4468690 -0.1989809 0.0679606 0.5446272 506.2227 1.0098505 a_bm_norm[18] 0.7130114 0.0167720 0.3808924 -0.0183411 0.4555032 0.6999494 0.9785093 1.4606787 515.7419 1.0099400 a_bm_norm[19] -2.7682656 0.0185762 0.6119694 -4.0524195 -3.1627036 -2.7420074 -2.3396622 -1.6568540 1085.2862 1.0034705 a_bm_norm[20] -0.4266745 0.0164341 0.3807487 -1.1703197 -0.6869354 -0.4300769 -0.1634403 0.3179506 536.7688 1.0086854 a_bm_norm[21] 0.0759374 0.0164646 0.3716052 -0.6445900 -0.1804491 0.0690284 0.3300406 0.8048668 509.4015 1.0097450 a_bm_norm[22] 0.8556946 0.0170212 0.3869695 0.1097358 0.5900103 0.8418314 1.1214378 1.6070843 516.8573 1.0098430 a_bm_norm[23] -0.4448254 0.0168243 0.3795906 -1.1861600 -0.7015128 -0.4495611 -0.1904081 0.3142150 509.0450 1.0093203 a_bm_norm[24] 1.8412536 0.0181239 0.4431351 0.9953701 1.5336795 1.8321119 2.1455095 2.7137327 597.8167 1.0077990 a_bm_norm[25] -0.9665475 0.0164092 0.4060287 -1.7640942 -1.2438024 -0.9655040 -0.6923165 -0.1708746 612.2672 1.0080942 a_bm_norm[26] 3.6380352 0.0217061 0.6156398 2.4743159 3.2128013 3.6315059 4.0489818 4.8858130 804.4349 1.0051971 a_bm_norm[27] -0.7932119 0.0166042 0.3960461 -1.5657851 -1.0630130 -0.7911402 -0.5210793 -0.0194242 568.9260 1.0087189 a_bm_norm[28] -3.1702347 0.0190775 0.6797668 -4.5427376 -3.6232001 -3.1358436 -2.6984293 -1.9344785 1269.6314 1.0025866 a_bm_norm[29] 0.9496324 0.0170548 0.3900386 0.2052225 0.6840586 0.9339381 1.2170634 1.7180512 523.0225 1.0091173 a_bm_norm[30] 1.5638220 0.0176164 0.4235736 0.7668162 1.2680706 1.5551584 1.8589646 2.3884795 578.1261 1.0079342 s 1.2134157 0.0048359 0.1705959 0.9255934 1.0939389 1.1964947 1.3135300 1.5874486 1244.4753 1.0014372 lp__ -5600.8573754 0.1490021 6.0848770 -5613.7917690 -5604.6669956 -5600.4448556 -5596.6089302 -5589.8922742 1667.7027 1.0024970 2.4 Results and Plots First lets get the HPDI of every parameter. Then we restrict to the algorithms, them to the slopes, then to the other parameters hpdi &lt;- get_HPDI_from_stanfit(probsuccess.fit) hpdi_oddsratio &lt;- hpdi hpdi_oddsratio$Mean &lt;- exp(hpdi$Mean) hpdi_oddsratio$HPDI.lower &lt;- exp(hpdi$HPDI.lower) hpdi_oddsratio$HPDI.higher &lt;- exp(hpdi$HPDI.higher) hpdi_oddsratio_algorithm &lt;- hpdi_oddsratio %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_alg\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_oddsratio_b_noise &lt;- hpdi_oddsratio %&gt;% dplyr::filter(str_detect(Parameter, &quot;b_noise\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_s &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;s&#39;) p_alg&lt;-ggplot(data=hpdi_oddsratio_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(title=&quot;Algorithm intercept&quot;, y=&quot;Odds ratio&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_alg + plot_annotation(title = &#39;HPDI interval for the algorithms odd ratio&#39;) p_noise &lt;- ggplot(data=hpdi_oddsratio_b_noise, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(title=&quot;Noise coefficient&quot;, y=&quot;Odds ratio&quot;, x=&quot;&quot;)+ coord_flip()+ theme(axis.text.y=element_blank()) p_noise + plot_annotation(title = &#39;HPDI interval for the noise coefficients odd ratio&#39;) p_s &lt;- ggplot(data=hpdi_s, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(title=&quot;Std benchmarks&quot;, y=&quot;Estimate&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_s + plot_annotation(title = &#39;HPDI interval for s&#39;) Creating an output table rename_pars &lt;- c( paste(rep(&#39;a_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;), paste(rep(&#39;b_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;), &#39;s&#39;) t&lt;-create_table_model(probsuccess.fit, c(a_alg, b_noise, &#39;s&#39;), rename_pars) saveRDS(t,&#39;./statscomp-paper/tables/datafortables/probsuccess-par-table.RDS&#39;) "],
["relative-improvement.html", "Chapter 3 Relative improvement 3.1 Data preparation 3.2 Stan model 3.3 Diagnosis 3.4 Results and Plots", " Chapter 3 Relative improvement Our next, model deals with relative improvement of the algorithms over a baseline in noiseless functions. This model is based on a normal linear regression. RQ What is the expected improvement of these algorithms against the Random Search in noiseless benchmark functions? For this question we will consider the Euclidean distance to the location of the closest global minima, instead of the final reward difference. 3.1 Data preparation We start importing the dataset dataset &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) Let’s select only the columns that interests us, in this case the Euclidean distance d&lt;- dataset %&gt;% dplyr::select(Algorithm, CostFunction, SD, Budget=MaxFevalPerDimensions, simNumber, EuclideanDistance, OptimizationSuccessful) %&gt;% dplyr::filter(OptimizationSuccessful &amp; SD==0) %&gt;% dplyr::select(-SD, -OptimizationSuccessful) Let’s first make this a wide data set based on the algorithm to make it easier to compute the relative improvement over the Random Search. We are also dropping the RandomSearch2 since there is no noise in the benchmark functions There are several ways that can be used to compute a relative improvement (and they will affect the result). The way we are using is to compare against the mean of distance of the 10 samples of the Random Search in each cost function for a specific budget. The way we are comparing is we divide the distance of each algorithm by the average distance of the random search. If this ratio is greater than 1 then random search is better, if smaller than 1 then the algorithm is better relativeImprovement &lt;- function(x, rs){ #x is the column #rs is the random search column ri &lt;- (rs-x)/rs ri&lt;-ifelse(ri &lt; -1, -1, ri) ri&lt;-ifelse(ri &gt; 1, 1, ri) return(ri) } d_wide &lt;- d %&gt;% tidyr::pivot_wider( names_from = Algorithm, values_from = EuclideanDistance) %&gt;% dplyr::select(-RandomSearch2) %&gt;% dplyr::group_by(CostFunction, Budget) %&gt;% dplyr::mutate(avgRandomSearch=mean(RandomSearch1)) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate_at(c(&quot;NelderMead&quot;, &quot;PSO&quot;, &quot;SimulatedAnnealing&quot;,&quot;CuckooSearch&quot;, &quot;DifferentialEvolution&quot;, &quot;CMAES&quot;), ~relativeImprovement(.x,rs=avgRandomSearch)) After we compute our metric we drop the Random Search column and we pivot_longer again to make the inference d_final &lt;- d_wide %&gt;% dplyr::select(-RandomSearch1, -avgRandomSearch) %&gt;% tidyr::pivot_longer( cols = c(&quot;NelderMead&quot;, &quot;PSO&quot;, &quot;SimulatedAnnealing&quot;,&quot;CuckooSearch&quot;, &quot;DifferentialEvolution&quot;, &quot;CMAES&quot;), names_to = &quot;Algorithm&quot;, values_to = &quot;y&quot;) %&gt;% dplyr::select(-simNumber) %&gt;% dplyr::mutate(AlgorithmID=create_index(Algorithm), CostFunctionID=create_index(CostFunction)) %&gt;% dplyr::select(Algorithm, AlgorithmID, CostFunction, CostFunctionID, Budget, y) #checking if there is any na -&gt; stan does not accept that find.na &lt;- d_final %&gt;% dplyr::filter(is.na(y)) bm&lt;-get_index_names_as_array(d_final$CostFunction) algorithms &lt;- get_index_names_as_array(d_final$Algorithm) Now we have our final dataset to use with Stan. Lets preview a sample of the data set kable(dplyr::sample_n(d_final,size=10), &quot;html&quot;,booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm AlgorithmID CostFunction CostFunctionID Budget y DifferentialEvolution 3 ChenV 3 20 0.741 DifferentialEvolution 3 DiscusN2 6 10000 1.000 SimulatedAnnealing 6 ChungReynoldsN2 4 20 -1.000 NelderMead 4 ExponentialN2 7 20 -0.683 SimulatedAnnealing 6 ChungReynoldsN2 4 100 -1.000 SimulatedAnnealing 6 ChenBird 2 1000 0.075 CMAES 1 Trigonometric1N6 26 1000 0.050 NelderMead 4 Trigonometric1N6 26 10000 0.172 SimulatedAnnealing 6 Schwefel2d26N6 19 100 -0.458 SimulatedAnnealing 6 RosenbrockRotatedN6 14 1000 0.501 3.2 Stan model The Stan model is specified in the file: './stanmodels/relativeimprovement.stan' print_stan_code(&#39;./stanmodels/relativeimprovement.stan&#39;) // Relative improvement model // Author: David Issa Mattos // Date: 17 June 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size real y[N_total]; // relative improvement variable //To model each algorithm independently int &lt;lower=1&gt; N_algorithm; // Number of algorithms int algorithm_id[N_total]; //vector that has the id of each algorithm //To model the influence of each benchmark int &lt;lower=1&gt; N_bm; int bm_id[N_total]; } parameters { real &lt;lower=0&gt; sigma;//std for the normal //Fixed effect real a_alg[N_algorithm];//the mean effect given by the algorithms // //Random effect. The effect of the benchmarks real a_bm_norm[N_bm];//the mean effect given by the base class type real&lt;lower=0&gt; s;//std for the random effects } model { real mu[N_total]; sigma ~ exponential(1); //Fixed effect a_alg ~ normal(0,1); // //Random effects s ~ exponential(1); a_bm_norm ~ normal(0,5); for (i in 1:N_total) { mu[i] = a_alg[algorithm_id[i]] + a_bm_norm[bm_id[i]]*s; } y ~ normal(mu, sigma); } Let’s compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations \"./data/relativeimprovement-data.RDS\" standata &lt;- list( N_total=nrow(d_final), y = d_final$y, N_algorithm = length(algorithms), algorithm_id = d_final$AlgorithmID, N_bm = length(bm), bm_id = d_final$CostFunctionID) saveRDS(standata, file = &quot;./data/relativeimprovement-data.RDS&quot;) For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately standata&lt;-readRDS(&quot;./data/relativeimprovement-data.RDS&quot;) relativeimprovement.fit &lt;- stan(file = &#39;./stanmodels/relativeimprovement.stan&#39;, data=standata, chains = 4, warmup = 200, iter = 2000) saveRDS(relativeimprovement.fit, file = &quot;./data/relativeimprovement-fit.RDS&quot;) 3.3 Diagnosis a_alg &lt;- c(&quot;a_alg[1]&quot;, &quot;a_alg[2]&quot;, &quot;a_alg[3]&quot;, &quot;a_alg[4]&quot;, &quot;a_alg[5]&quot;, &quot;a_alg[6]&quot;) rstan::traceplot(relativeimprovement.fit, pars=a_alg) rstan::traceplot(relativeimprovement.fit, pars=c(&#39;s&#39;,&#39;sigma&#39;)) Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling. kable(summary(relativeimprovement.fit)$summary) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat sigma 0.6366992 0.0000454 0.0047854 0.6272973 0.6335023 0.6367213 0.6398886 0.6460897 11123.2858 0.999663 a_alg[1] 0.1517965 0.0011766 0.0310153 0.0890402 0.1315669 0.1515736 0.1720076 0.2131436 694.8023 1.010485 a_alg[2] -0.3765757 0.0012145 0.0308803 -0.4362484 -0.3974145 -0.3765244 -0.3560475 -0.3157079 646.4589 1.012039 a_alg[3] 0.3032118 0.0011403 0.0311283 0.2418509 0.2830412 0.3030670 0.3234544 0.3656765 745.2010 1.011560 a_alg[4] -0.6398181 0.0011550 0.0309328 -0.7010332 -0.6602053 -0.6395958 -0.6197929 -0.5785804 717.2631 1.010893 a_alg[5] 0.3212411 0.0011688 0.0310915 0.2604697 0.3007525 0.3213155 0.3417438 0.3816100 707.6620 1.011001 a_alg[6] -0.5693807 0.0011457 0.0309980 -0.6312980 -0.5898352 -0.5695445 -0.5495347 -0.5063644 731.9811 1.010142 a_bm_norm[1] -2.7137114 0.0416885 1.5665895 -5.8224324 -3.7327766 -2.6736342 -1.6686107 0.2776190 1412.1390 1.004527 a_bm_norm[2] -10.8958837 0.0554098 2.0632999 -15.1207865 -12.2444144 -10.8215307 -9.4621775 -7.0769171 1386.6027 1.003124 a_bm_norm[3] 4.2583819 0.0385214 1.6332886 1.1117384 3.1391281 4.2362438 5.3542234 7.5718072 1797.7158 1.004829 a_bm_norm[4] 0.7112590 0.0428340 1.5408722 -2.3646658 -0.3207764 0.7193666 1.7256372 3.7018440 1294.0657 1.005084 a_bm_norm[5] -5.7656983 0.0431004 1.7041312 -9.2596729 -6.8551277 -5.7106639 -4.5908359 -2.5530455 1563.3011 1.002572 a_bm_norm[6] 4.2496820 0.0414842 1.6438047 1.1100909 3.1394173 4.1933720 5.3276540 7.5493153 1570.1272 1.007179 a_bm_norm[7] -0.2674616 0.0369455 1.5162217 -3.3010115 -1.2763273 -0.2536588 0.7311207 2.6874394 1684.2293 1.005261 a_bm_norm[8] 5.6344824 0.0401936 1.7039969 2.4599223 4.4498948 5.5829061 6.7546531 9.1313990 1797.3156 1.003865 a_bm_norm[9] 2.3486823 0.0365820 1.5733714 -0.6677979 1.2810815 2.3172149 3.3908362 5.4734946 1849.8131 1.005487 a_bm_norm[10] 1.6087046 0.0378888 1.5388783 -1.4414791 0.5689259 1.5979130 2.6324298 4.6692221 1649.6313 1.005010 a_bm_norm[11] 4.3359572 0.0400394 1.6234754 1.2474252 3.2273711 4.3025935 5.4012772 7.5917445 1644.0567 1.004376 a_bm_norm[12] 3.3231669 0.0380437 1.5581674 0.3842329 2.2473012 3.2775423 4.3421298 6.5170015 1677.4984 1.004492 a_bm_norm[13] -8.7863772 0.0495466 1.8703483 -12.5734195 -10.0168608 -8.7316873 -7.4936928 -5.3044054 1425.0092 1.002819 a_bm_norm[14] 4.3965769 0.0398836 1.6356215 1.2509473 3.2929197 4.3874897 5.4634265 7.6869788 1681.8130 1.005157 a_bm_norm[15] -5.4213624 0.0424027 1.6621547 -8.7825665 -6.5371309 -5.3809169 -4.2789899 -2.2428167 1536.5824 1.003424 a_bm_norm[16] 0.5037543 0.0349947 1.5393684 -2.4795947 -0.5253227 0.4943375 1.5307805 3.5780664 1934.9966 1.002675 a_bm_norm[17] 4.0776233 0.0418592 1.5962764 1.0589818 2.9720643 4.0549310 5.1239776 7.2967120 1454.2348 1.005255 a_bm_norm[18] 3.8001474 0.0386611 1.6026555 0.8170766 2.6999973 3.7310589 4.8383907 7.1187954 1718.4334 1.004670 a_bm_norm[19] -2.8913038 0.0423698 1.5655264 -6.0602853 -3.9014872 -2.8552779 -1.8200818 0.0302975 1365.2387 1.005471 a_bm_norm[20] 0.3825050 0.0410052 1.5538486 -2.7183712 -0.6445357 0.3959057 1.3944785 3.3949192 1435.9492 1.004422 a_bm_norm[21] -2.8360559 0.0390764 1.5588204 -5.9845535 -3.8691546 -2.8033550 -1.8002926 0.1867086 1591.3372 1.004338 a_bm_norm[22] 5.8450623 0.0407720 1.6957078 2.7541864 4.6792436 5.7936697 6.9324970 9.3939160 1729.7326 1.003963 a_bm_norm[23] -6.3745110 0.0440180 1.7247972 -9.9118463 -7.5101071 -6.3209794 -5.1551930 -3.1383556 1535.3812 1.002384 a_bm_norm[24] 1.2950268 0.0362686 1.5578214 -1.7352214 0.2458700 1.2606755 2.3310578 4.4108179 1844.9033 1.003614 a_bm_norm[25] -3.7348643 0.0432295 1.5722999 -6.9112210 -4.7862040 -3.6838769 -2.6456579 -0.7579575 1322.8509 1.004567 a_bm_norm[26] 6.9776767 0.0435961 1.7674427 3.6526650 5.7696341 6.9033355 8.1201421 10.5466427 1643.5993 1.005146 a_bm_norm[27] -5.4455812 0.0432887 1.6583715 -8.8491366 -6.5232091 -5.3929347 -4.3027325 -2.4056948 1467.6252 1.003268 a_bm_norm[28] -1.9200252 0.0377029 1.5490553 -5.0022050 -2.9627591 -1.9010092 -0.8716976 1.0580959 1688.0430 1.003941 a_bm_norm[29] -2.6777911 0.0378873 1.5667798 -5.8967952 -3.7023463 -2.6256191 -1.6100436 0.2458392 1710.1283 1.003846 a_bm_norm[30] 5.4409271 0.0402352 1.6923063 2.2384787 4.2960018 5.3998164 6.5270230 8.8830024 1769.0738 1.005596 s 0.0290267 0.0001202 0.0043209 0.0219523 0.0260244 0.0285486 0.0315318 0.0388776 1292.9627 1.002235 lp__ -455.7124747 0.1573456 5.8454274 -468.2114406 -459.4107452 -455.4265434 -451.6435633 -445.2134104 1380.1405 1.001604 3.4 Results and Plots First lets get the HPDI of every parameter. Then we restrict to the algorithms, them to the slopes, then to the hpdi &lt;- get_HPDI_from_stanfit(relativeimprovement.fit) hpdi_algorithm &lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_alg\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_other_parameters &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;s&#39; | Parameter==&#39;sigma&#39;) p_alg&lt;-ggplot(data=hpdi_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_alg + plot_annotation(title = &#39;HPDI interval for the algorithms&#39;) p_others &lt;- ggplot(data=hpdi_other_parameters, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_others + plot_annotation(title = &#39;HPDI interval&#39;) Creating an output table rename_pars &lt;- c(paste(rep(&#39;a_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;),&#39;s&#39;,&#39;sigma&#39;) t&lt;-create_table_model(relativeimprovement.fit, c(a_alg, &#39;s&#39;, &#39;sigma&#39;),rename_pars) saveRDS(t,&#39;./statscomp-paper/tables/datafortables/relativeimprovement-par-table.RDS&#39;) "],
["ranking.html", "Chapter 4 Ranking 4.1 Data preparation 4.2 Stan model 4.3 Diagnosis 4.4 Results and Plots", " Chapter 4 Ranking In this section, we will consider the Bradley-Terry Model for ranking algorithms in the fixed budget of 10,000 function evaluations per dimension and controlling for noise and the effect of benchmark functions How can we rank algorithm different optimization algorithms given a budget of 10,000 evaluations per dimension in noisy benchmarks? 4.1 Data preparation We start importing the dataset dataset &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) The BT model formulation that we use has a specific data format, where we have one column with algo_0 (with index of each algorithm) another column with algo_1 and a third column with who won (algo 0 or algo 1), First lets select only the data that we are interested and create ranking by the each run in each group (by the simNumber). To avoid ties (dealing with those on next session) we will rank ties randomly d1 &lt;- dataset %&gt;% dplyr::select(Algorithm, CostFunction, SD, Budget=MaxFevalPerDimensions, simNumber, TrueRewardDifference, OptimizationSuccessful) %&gt;% dplyr::filter(OptimizationSuccessful &amp; Budget==10000 &amp; SD==3.0) %&gt;% dplyr::select(-Budget, -OptimizationSuccessful, -SD) %&gt;% dplyr::group_by(CostFunction, simNumber) %&gt;% dplyr::mutate(rankReward=rank(TrueRewardDifference, ties.method = &#39;random&#39;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-TrueRewardDifference) kable(dplyr::sample_n(d1,size=10), booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm CostFunction simNumber rankReward NelderMead SphereN6 7 8 CuckooSearch ChungReynoldsN2 5 6 CuckooSearch Giunta 2 5 RandomSearch2 ExponentialN2 7 1 NelderMead SalomonN2 1 7 CuckooSearch BentCigarN6 5 6 RandomSearch2 Tripod 8 4 NelderMead StrechedVSineWave2N 0 3 RandomSearch2 Giunta 0 2 SimulatedAnnealing Schwefel2d23N6 4 8 Now to compare the ranks we need to pivot wider the data frame and based on that we will expand to the dataset in the appropriated format d1_wide &lt;- d1 %&gt;% tidyr::pivot_wider(names_from = Algorithm, values_from=rankReward) kable(dplyr::sample_n(d1_wide,size=10), booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) CostFunction simNumber NelderMead PSO SimulatedAnnealing CuckooSearch DifferentialEvolution RandomSearch1 RandomSearch2 CMAES QingN2 8 7 3 8 6 1 4 2 5 Schwefel2d4N6 9 8 3 7 6 2 4 5 1 ChenBird 1 5 6 7 2 1 3 4 8 DiscusN2 8 7 5 4 6 2 1 3 8 LunacekBiRastriginN6 2 8 1 5 7 2 4 6 3 Damavandi 2 8 6 5 7 4 2 1 3 ChenV 3 7 3 2 6 8 4 1 5 ChenV 7 6 4 2 7 8 1 3 5 Schwefel2d21N6 5 7 6 8 5 1 4 3 2 ThreeHumpCamelBack 3 8 6 2 7 5 3 1 4 Now we need to modify this data set and expand it so we have the pairwise comparisons First let’s get the number of algorithms and create combination of all possible 2 by 2 comparisons without repeating algorithms &lt;- get_index_names_as_array(d1$Algorithm) n_algorithms &lt;- length(algorithms) comb &lt;- gtools::combinations(n=n_algorithms, r=2, v=seq(1:n_algorithms), repeats.allowed = F) The pairs combinations looks like this (for algo_0 and algo_1): kable(comb, booktabs=T) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) 1 2 1 3 1 4 1 5 1 6 1 7 1 8 2 3 2 4 2 5 2 6 2 7 2 8 3 4 3 5 3 6 3 7 3 8 4 5 4 6 4 7 4 8 5 6 5 7 5 8 6 7 6 8 7 8 Note that each row of d_wide will be expanded into 28 rows. Giving a dataset with a total of 8400 rows. The following code can a bit slow to run due to the double for loops (there is probably a way to vectorize this and make it run faster), but for building this appendix we will not run, instead we will run it once, save this data, and load it when needed. It takes a couple of minutes but if you have a lot of data and algorithms it can easily go for hours We will use a progress bar to follow the data frame creation. 1- We initialize a tibble data frame 2- First we loop through the wide data frame d1_wide row by row 3- For each row we will loop through the different combinations in the comb variable to create the rows of the data frame. We add each row to the initial dataframe pb &lt;- progress::progress_bar$new(format = &quot;[:bar] :current/:total (:percent)&quot;, total = nrow(d1_wide)) df_out &lt;- dplyr::tribble(~algo0_name, ~algo0, ~algo1_name, ~algo1, ~y, ~simNumber, ~CostFunction) for(i in 1:nrow(d1_wide)) { current_row &lt;- d1_wide[i,] for(j in 1:nrow(comb)){ comb_row &lt;- comb[j,] algo0_name &lt;- algorithms[comb_row[1]] algo0 &lt;- comb_row[1] algo0_rank &lt;- current_row[[1,algo0_name]] algo1_name &lt;- algorithms[comb_row[2]] algo1 &lt;- comb_row[2] algo1_rank &lt;- current_row[[1,algo1_name]] diff_rank &lt;- algo1_rank - algo0_rank y &lt;- ifelse(diff_rank&lt;0, 1, 0) df_out &lt;- add_row(df_out, algo0_name=algo0_name, algo0=algo0, algo1_name=algo1_name, algo1=algo1, y=y, simNumber=current_row$simNumber, CostFunction=current_row$CostFunction) } pb$tick() } saveRDS(df_out, file=&quot;./data/ranking.RDS&quot;) Visualizing how the data frame looks like df_out &lt;- readRDS(&quot;./data/ranking.RDS&quot;) kable(dplyr::sample_n(df_out,size=10), &quot;html&quot;, booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) algo0_name algo0 algo1_name algo1 y simNumber CostFunction CuckooSearch 2 SimulatedAnnealing 8 1 6 SalomonN2 NelderMead 4 SimulatedAnnealing 8 0 7 SalomonN2 RandomSearch2 7 SimulatedAnnealing 8 0 9 RosenbrockRotatedN6 DifferentialEvolution 3 SimulatedAnnealing 8 0 1 Tripod CMAES 1 SimulatedAnnealing 8 0 6 Price1 RandomSearch1 6 RandomSearch2 7 1 6 ChenBird DifferentialEvolution 3 SimulatedAnnealing 8 0 1 Schwefel2d21N6 CMAES 1 CuckooSearch 2 1 0 ChenV CuckooSearch 2 RandomSearch1 6 1 6 Price1 CuckooSearch 2 SimulatedAnnealing 8 0 0 Schwefel2d26N6 4.2 Stan model The Stan model is specified in the file: './stanmodels/rankingmodel.stan' print_stan_code(&#39;./stanmodels/rankingmodel.stan&#39;) // Relative improvement model // Author: David Issa Mattos // Date: 22 June 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size int y[N_total]; //variable that indicates which one wins algo0 oor algo 1 int &lt;lower=1&gt; N_algorithm; // Number of algorithms int &lt;lower=1&gt; algo0[N_total]; int &lt;lower=1&gt; algo1[N_total]; // //To model the influence of each benchmark // int &lt;lower=1&gt; N_bm; // int bm_id[N_total]; } parameters { real a_alg[N_algorithm]; //Latent variable that represents the strength value of each algorithm } model { real p[N_total]; a_alg ~ normal(0,5); for (i in 1:N_total) { p[i] = a_alg[algo1[i]] - a_alg[algo0[i]]; } y ~ bernoulli_logit(p); } Let’s compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations \"./data/rankingmodel-data.RDS\" standata &lt;- list( N_total=nrow(df_out), y = as.integer(df_out$y), N_algorithm = length(algorithms), algo0=df_out$algo0, algo1=df_out$algo1 ) saveRDS(standata, file = &quot;./data/rankingmodel-data.RDS&quot;) For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately standata&lt;-readRDS(&quot;./data/rankingmodel-data.RDS&quot;) ranking.fit &lt;- stan(file = &#39;./stanmodels/rankingmodel.stan&#39;, data=standata, chains = 4, warmup = 200, iter = 3000) saveRDS(ranking.fit, file = &quot;./data/ranking-fit.RDS&quot;) 4.3 Diagnosis rstan::traceplot(ranking.fit) Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling. kable(summary(ranking.fit)$summary) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat a_alg[1] 0.4084384 0.0687584 1.720812 -2.858958 -0.7676065 0.3440869 1.5699504 3.812734 626.3471 1.005165 a_alg[2] -0.1774591 0.0687564 1.720583 -3.426869 -1.3463006 -0.2412592 0.9817933 3.234688 626.2172 1.005184 a_alg[3] 1.0094798 0.0687726 1.720875 -2.247081 -0.1657261 0.9504481 2.1712578 4.414507 626.1349 1.005142 a_alg[4] -1.5377430 0.0688034 1.721564 -4.786752 -2.7119752 -1.6038727 -0.3785720 1.864659 626.0755 1.005183 a_alg[5] 0.9047158 0.0687920 1.721010 -2.359160 -0.2615130 0.8375588 2.0725945 4.309449 625.8795 1.005187 a_alg[6] 0.2483808 0.0688069 1.720572 -3.012020 -0.9181424 0.1910053 1.4119977 3.641228 625.2911 1.005193 a_alg[7] 0.2707818 0.0687883 1.721571 -2.993985 -0.8985814 0.2057360 1.4383461 3.682501 626.3548 1.005131 a_alg[8] -0.7029246 0.0687277 1.720280 -3.976641 -1.8655727 -0.7690434 0.4648929 2.700285 626.5198 1.005145 lp__ -4760.9935612 0.0390249 1.998507 -4765.718702 -4762.0915197 -4760.6613267 -4759.5343449 -4758.115441 2622.5690 1.000402 4.4 Results and Plots First let’s get the HPDI interval for the “strength” parameters. Then we will sample the posterior and rank them and present the ranks with their respective posteriors. hpdi &lt;- get_HPDI_from_stanfit(ranking.fit) hpdi_algorithm &lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_alg\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels p_alg&lt;-ggplot(data=hpdi_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_alg + plot_annotation(title = &#39;HPDI interval for the algorithms strength&#39;) Computing the ranks posterior &lt;- rstan::extract(ranking.fit) a_alg &lt;- as_tibble(posterior$a_alg) colnames(a_alg) &lt;- algorithms #sampling from the posterior s &lt;- dplyr::sample_n(a_alg, size = 1000, replace=T) s &lt;- dplyr::mutate(s, rown = row_number()) wide_s &lt;- tidyr::pivot_longer(s, cols=all_of(algorithms), names_to = &quot;Algorithm&quot;, values_to = &quot;a_alg&quot;) rank_df &lt;- wide_s %&gt;% dplyr::group_by(rown) %&gt;% dplyr::mutate(Rank = rank(-a_alg, ties.method = &#39;random&#39;)) %&gt;% dplyr::ungroup() %&gt;% dplyr::select(-a_alg) %&gt;% dplyr::group_by(Algorithm) %&gt;% dplyr::summarise(MedianRank = median(Rank), VarianceRank = var(Rank)) %&gt;% dplyr::arrange(MedianRank) rank_df_table &lt;- rank_df colnames(rank_df_table) &lt;- c(&quot;Algorithm&quot;,&quot;Median Rank&quot;, &quot;Variance of the Rank&quot;) kable(rank_df_table, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) Algorithm Median Rank Variance of the Rank DifferentialEvolution 1 0.0599640 PSO 2 0.0599640 CMAES 3 0.0167918 RandomSearch2 4 0.2460450 RandomSearch1 5 0.2422863 CuckooSearch 6 0.0000000 SimulatedAnnealing 7 0.0000000 NelderMead 8 0.0000000 a_alg &lt;- c(&quot;a_alg[1]&quot;, &quot;a_alg[2]&quot;, &quot;a_alg[3]&quot;, &quot;a_alg[4]&quot;, &quot;a_alg[5]&quot;, &quot;a_alg[6]&quot;, &quot;a_alg[7]&quot;, &quot;a_alg[8]&quot;) rename_pars &lt;- c(paste(rep(&#39;a_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;)) t&lt;-create_table_model(ranking.fit, c(a_alg),rename_pars) saveRDS(t,&#39;./statscomp-paper/tables/datafortables/ranking-par-table.RDS&#39;) "],
["time-to-complete.html", "Chapter 5 Time to complete 5.1 Data preparation 5.2 Stan model 5.3 Diagnosis 5.4 Results and Plots", " Chapter 5 Time to complete In this section, we will consider the Cox’s Proportional Hazard model for analyzing the time to converge to a a solution (in number of iterations). *RQ1: **What is the average number of function evaluations that it takes for an algorithm to converge to a solution at a precision of \\(\\epsilon=0.1\\)? Here we will utilize a window of 100,000 function evaluations per dimension (the budget). RQ2: What is the impact of noise in the number of function evaluations? 5.1 Data preparation We start importing the dataset dataset &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) Filtering the data that we want and applying some transformations d &lt;- dataset %&gt;% dplyr::filter(OptimizationSuccessful==TRUE &amp; MaxFevalPerDimensions==100000 &amp; (Algorithm==&quot;PSO&quot;|Algorithm==&quot;CMAES&quot;|Algorithm==&quot;DifferentialEvolution&quot;|Algorithm==&quot;RandomSearch2&quot;)) %&gt;% dplyr::select(Algorithm, CostFunction, Event=&quot;SolveAt1e-1&quot;, simNumber, Ndimensions, SD, SolvedAtIteration=&quot;SolveEarlierAt1e-1&quot;) %&gt;% dplyr::mutate(y=SolvedAtIteration/Ndimensions, Event=as.integer(Event), CostFunctionID=create_index(CostFunction), AlgorithmID=create_index(Algorithm)) %&gt;% dplyr::select(Algorithm, AlgorithmID, CostFunction, CostFunctionID, SD, Event, y,-simNumber,-SolvedAtIteration, -Ndimensions) algorithms&lt;-get_index_names_as_array(d$Algorithm) bm &lt;- get_index_names_as_array(d$CostFunction) The data should look like this: kable(dplyr::sample_n(d,size=10),&quot;html&quot;, booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm AlgorithmID CostFunction CostFunctionID SD Event y CMAES 1 DiscusN2 6 3 0 NA PSO 3 Schwefel2d4N6 20 0 0 NA CMAES 1 Price1 12 0 1 27.000 RandomSearch2 4 Schwefel2d20N2 16 3 0 NA PSO 3 Schwefel2d4N6 20 0 1 12580.333 RandomSearch2 4 SphereN6 22 3 0 NA PSO 3 Price1 12 3 0 57.500 PSO 3 SphereN6 22 3 1 40.167 RandomSearch2 4 RosenbrockRotatedN6 14 3 0 NA RandomSearch2 4 WhitleyN6 28 3 0 NA 5.2 Stan model The Stan model is specified in the file: './stanmodels/timetoconverge.stan' print_stan_code(&#39;./stanmodels/timetoconverge.stan&#39;) // Time to converge, Cox regression model // Author: David Issa Mattos // Date: 23 June 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size real y[N_total]; // iteration where it was solved int event[N_total]; // Indicates if the event occured or not //To model each algorithm independently int &lt;lower=1&gt; N_algorithm; // Number of algorithms int algorithm_id[N_total]; //vector that has the id of each algorithm //To model the influence of the noise real x_noise[N_total]; //To model the influence of each benchmark int &lt;lower=1&gt; N_bm; int bm_id[N_total]; } parameters { //Fixed effect real a_alg[N_algorithm];//the mean effect given by the algorithms real b_noise[N_algorithm];//effect of noise // //Random effect. The effect of the benchmarks real a_bm_norm[N_bm];//the mean effect given by the base class type real&lt;lower=0&gt; s;//std for the random effects } model { //Fixed effect a_alg ~ normal(0,10); // //Random effects s ~ exponential(0.1); a_bm_norm ~ normal(0,10); for (i in 1:N_total) { //uncensored data if(event[i]==1) target += exponential_lpdf(y[i] | exp(a_alg[algorithm_id[i]] + s*a_bm_norm[bm_id[i]] + b_noise[algorithm_id[i]]*x_noise[i])); //censored data if(event[i]==0) target += exponential_lccdf(y[i] | exp(a_alg[algorithm_id[i]] + s*a_bm_norm[bm_id[i]] + b_noise[algorithm_id[i]]*x_noise[i])); } } Let’s compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations \"./data/timetoconverge-data.RDS\" Note that stan does not support NA in the data, so we have two options… We either replace NA for a value and add conditionals in the model (note that this value will not be used). Or we separate the data frame in two parts, censored and not not-censored. We will do the first approach replacing the NA by 0. dstan&lt;-d %&gt;% dplyr::mutate(y=replace_na(y,0)) standata &lt;- list( N_total=nrow(dstan), y = dstan$y, event = dstan$Event, x_noise = d$SD, N_algorithm = length(algorithms), algorithm_id = dstan$AlgorithmID, N_bm = length(bm), bm_id = d$CostFunctionID ) saveRDS(standata, file = &quot;./data/timetoconverge-data.RDS&quot;) For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately standata&lt;-readRDS(&quot;./data/timetoconverge-data.RDS&quot;) timetoconverge_fit &lt;- stan(file = &#39;./stanmodels/timetoconverge.stan&#39;, data=standata, chains = 4, warmup = 200, iter = 3000) saveRDS(timetoconverge_fit, file = &quot;./data/timetoconverge-fit.RDS&quot;) 5.3 Diagnosis a_alg &lt;- c(&quot;a_alg[1]&quot;, &quot;a_alg[2]&quot;, &quot;a_alg[3]&quot;, &quot;a_alg[4]&quot;) b_noise &lt;- c(&quot;b_noise[1]&quot;, &quot;b_noise[2]&quot;, &quot;b_noise[3]&quot;, &quot;b_noise[4]&quot;) rstan::traceplot(timetoconverge_fit, pars=a_alg) rstan::traceplot(timetoconverge_fit, pars=b_noise) rstan::traceplot(timetoconverge_fit, pars=&#39;s&#39;) Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling. kable(summary(timetoconverge_fit)$summary) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat a_alg[1] -5.0613996 0.0157814 0.4560554 -5.9648678 -5.3565507 -5.0671857 -4.7771710 -4.1191871 835.1080 1.0059471 a_alg[2] -6.3414200 0.0157765 0.4539939 -7.2424630 -6.6317677 -6.3496712 -6.0581270 -5.4164012 828.0941 1.0067278 a_alg[3] -6.2728790 0.0159023 0.4566207 -7.1798165 -6.5678209 -6.2849249 -5.9858838 -5.3405945 824.4971 1.0064357 a_alg[4] -8.9236906 0.0160332 0.4656145 -9.8527233 -9.2297362 -8.9294489 -8.6299670 -7.9744463 843.3587 1.0065466 b_noise[1] -0.7860677 0.0006585 0.0678371 -0.9215398 -0.8307742 -0.7847312 -0.7398537 -0.6572384 10612.7997 0.9999942 b_noise[2] -0.9581764 0.0005810 0.0659688 -1.0919712 -1.0009872 -0.9569834 -0.9131543 -0.8322398 12892.0779 1.0000365 b_noise[3] -0.6789703 0.0006821 0.0611909 -0.8038079 -0.7194895 -0.6772081 -0.6375569 -0.5625861 8047.7954 0.9999387 b_noise[4] -0.4095699 0.0007824 0.0721207 -0.5565661 -0.4568533 -0.4082483 -0.3602928 -0.2740744 8497.8242 1.0000011 a_bm_norm[1] -7.0877389 0.0749785 2.3831719 -11.9757364 -8.6159193 -6.9973773 -5.4510546 -2.6669323 1010.2686 1.0082755 a_bm_norm[2] -5.9245341 0.0741209 4.2518131 -15.6367452 -8.4127182 -5.4917162 -2.9632739 1.1536322 3290.5399 1.0014992 a_bm_norm[3] -6.4322669 0.0718337 2.2904443 -11.0973986 -7.9441332 -6.3896121 -4.8402558 -2.1235828 1016.6778 1.0086309 a_bm_norm[4] 0.2645846 0.0652792 1.9160067 -3.5999621 -0.9711798 0.2815428 1.5247146 3.9836167 861.4773 1.0060705 a_bm_norm[5] -7.1089601 0.0749560 2.8684430 -13.1196102 -8.9776989 -6.9803076 -5.1185665 -1.8397802 1464.4666 1.0053574 a_bm_norm[6] -9.8906483 0.0784257 2.4163333 -14.8309217 -11.4851003 -9.8269148 -8.2255915 -5.3486789 949.2849 1.0095475 a_bm_norm[7] 27.3747983 0.1216245 4.2044063 19.3919625 24.4791772 27.3492651 30.2644685 35.5916931 1194.9987 1.0014577 a_bm_norm[8] 17.6615243 0.0921898 3.0984475 11.6936753 15.5639385 17.6473338 19.7271769 23.6888205 1129.5944 1.0008837 a_bm_norm[9] 0.1504036 0.0915617 10.0544727 -19.8795982 -6.5489149 0.0575604 7.0376056 20.0162593 12058.4285 0.9997498 a_bm_norm[10] -4.4694467 0.0687983 2.0355906 -8.5651224 -5.7852747 -4.4065630 -3.1022936 -0.5689452 875.4383 1.0087418 a_bm_norm[11] -5.4379287 0.0701770 2.3044786 -10.1394427 -6.9592956 -5.3795716 -3.8705804 -1.0531343 1078.3414 1.0066421 a_bm_norm[12] 9.2048973 0.0720827 2.2941741 4.7324357 7.6721227 9.2162178 10.7585273 13.7363416 1012.9567 1.0014343 a_bm_norm[13] -1.5298311 0.0662179 1.9885925 -5.5559351 -2.8125576 -1.4943839 -0.1883472 2.2895267 901.8630 1.0069762 a_bm_norm[14] -5.7866173 0.0700067 2.1671965 -10.1555018 -7.1683828 -5.7436617 -4.3204160 -1.6094038 958.3364 1.0082794 a_bm_norm[15] -6.0465802 0.0725298 2.2009008 -10.5609547 -7.4800582 -5.9742389 -4.5277332 -1.8971065 920.8065 1.0090590 a_bm_norm[16] -1.5955184 0.0659452 1.9753904 -5.6179865 -2.8619788 -1.5684474 -0.2656631 2.2091017 897.3037 1.0071111 a_bm_norm[17] -8.3947538 0.0762844 2.2904871 -13.1127504 -9.8702466 -8.3122852 -6.8348196 -4.0266879 901.5379 1.0092575 a_bm_norm[18] 1.9662528 0.0643692 1.9323805 -1.9650423 0.7186888 1.9915568 3.2605817 5.7014489 901.2164 1.0045200 a_bm_norm[19] -5.1319274 0.0718555 3.0224655 -11.5147855 -7.0374354 -4.9572509 -3.0605805 0.3507493 1769.3062 1.0049483 a_bm_norm[20] -4.1510092 0.0679660 2.1149226 -8.4905133 -5.5208133 -4.1004063 -2.7190834 -0.0952630 968.2912 1.0073867 a_bm_norm[21] -6.0097069 0.0709157 2.1251703 -10.3425980 -7.3809040 -5.9256659 -4.5776428 -1.9232086 898.0553 1.0085248 a_bm_norm[22] 8.0958044 0.0700051 2.2265575 3.6424167 6.6261168 8.1058766 9.5767015 12.4526855 1011.5993 1.0015720 a_bm_norm[23] -5.5358192 0.0701564 2.1652251 -9.9602000 -6.9389123 -5.4949951 -4.0825698 -1.4006888 952.5135 1.0086023 a_bm_norm[24] 8.4523112 0.0708775 2.2470266 3.9762111 6.9469151 8.4647626 9.9435050 12.9039005 1005.0774 1.0012439 a_bm_norm[25] -10.5279574 0.0802152 2.4963522 -15.7209550 -12.1311350 -10.4380456 -8.8068753 -5.8655591 968.4979 1.0096112 a_bm_norm[26] 21.5078177 0.1033759 3.5066005 14.7823934 19.1123022 21.4775763 23.8859476 28.2789321 1150.6250 1.0011242 a_bm_norm[27] -3.2335153 0.0673942 2.1723149 -7.7081539 -4.6367134 -3.1696124 -1.7798582 0.9014833 1038.9650 1.0069983 a_bm_norm[28] -8.5321269 0.0712292 4.1167821 -17.3364948 -11.1489733 -8.2104286 -5.5897781 -1.5108541 3340.4129 1.0020824 a_bm_norm[29] 3.0863179 0.0653996 2.0160957 -0.9445710 1.7852036 3.0724728 4.4343885 6.9619422 950.3245 1.0033837 a_bm_norm[30] 7.8416935 0.0702258 2.2052631 3.4507164 6.3697465 7.8285057 9.3278814 12.1223456 986.1133 1.0018694 s 0.2467678 0.0010139 0.0357911 0.1900351 0.2213592 0.2428182 0.2673082 0.3268829 1246.1026 1.0043498 lp__ -5469.5295707 0.1407376 5.6774072 -5481.5884801 -5473.1698647 -5469.2481459 -5465.5160240 -5459.2165106 1627.3454 1.0015679 5.4 Results and Plots First lets get the HPDI of every parameter. Then we restrict to the algorithms, them to the slopes, then to the parameter s hpdi &lt;- get_HPDI_from_stanfit(timetoconverge_fit) hpdi_algorithm &lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_alg\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_noise&lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;b_noise\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_s &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;s&#39;) p_alg&lt;-ggplot(data=hpdi_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;a_alg&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_alg + plot_annotation(title = &#39;HPDI interval for the algorithms&#39;) p_noise&lt;-ggplot(data=hpdi_noise, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;b_noise&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_noise + plot_annotation(title = &#39;HPDI interval for noise coefficient&#39;) p_s &lt;- ggplot(data=hpdi_s, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_s + plot_annotation(title = &#39;HPDI interval std of the benchmarks&#39;) Table for the hazard ratio hr_table &lt;- tibble( &quot;Algorithm&quot; = algorithms, &quot;Baseline Coefficient&quot; = exp(hpdi_algorithm$Mean), &quot;Noise HR&quot; = exp(hpdi_noise$Mean)) kable(hr_table, booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm Baseline Coefficient Noise HR CMAES 0.006 0.456 DifferentialEvolution 0.002 0.384 PSO 0.002 0.507 RandomSearch2 0.000 0.664 Creating an output table rename_pars &lt;- c(paste(rep(&#39;a_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;), paste(rep(&#39;b_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;),&#39;s&#39;) t&lt;-create_table_model(timetoconverge_fit, c(a_alg, b_noise, &#39;s&#39;),rename_pars) saveRDS(t,&#39;./statscomp-paper/tables/datafortables/timetoconverge-par-table.RDS&#39;) "],
["multiple-group-comparison.html", "Chapter 6 Multiple-group comparison 6.1 Data preparation 6.2 Stan model 6.3 Diagnosis 6.4 Results and Plots", " Chapter 6 Multiple-group comparison We present here the Stan version of the BEST (Bayesian Estimation Supersedes the t Test) from John K. Kruschke. We will consider the following research question RQ4-a: What is the average number of function evaluations that it takes for an algorithm to converge to a solution at a precision of \\(\\epsilon=0.1\\), with a budget of 100,000 function evaluations per dimension? RQ4-b: What is the impact of noise in the number of function evaluations that it takes for an algorithm to converge to a solution at a precision of \\(\\epsilon=0.1\\), with a budget of 100,000 function evaluations per dimension? 6.1 Data preparation We start importing the dataset dataset &lt;- readr::read_csv(&#39;./data/statscomp.csv&#39;) Filtering the data that we want and applying some transformations d &lt;- dataset %&gt;% dplyr::filter( OptimizationSuccessful==TRUE &amp; (Algorithm==&quot;PSO&quot; | Algorithm==&quot;RandomSearch1&quot; | Algorithm==&quot;DifferentialEvolution&quot;)) %&gt;% dplyr::select(Algorithm, CostFunction, TimeToComplete, simNumber, MaxFeval) %&gt;% dplyr::mutate(y=10000*TimeToComplete/MaxFeval, CostFunctionID=create_index(CostFunction), AlgorithmID=create_index(Algorithm)) %&gt;% dplyr::select(Algorithm, AlgorithmID, CostFunction, CostFunctionID, y,-simNumber, -MaxFeval) algorithms&lt;-get_index_names_as_array(d$Algorithm) bm &lt;- get_index_names_as_array(d$CostFunction) The data should look like this: kable(dplyr::sample_n(d,size=10), &quot;html&quot;,booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Algorithm AlgorithmID CostFunction CostFunctionID y PSO 2 LunacekBiRastriginN6 9 1.137 RandomSearch1 3 StrechedVSineWave2N 23 0.232 RandomSearch1 3 WhitleyN6 28 1.636 RandomSearch1 3 StrechedVSineWave2N 23 0.221 DifferentialEvolution 1 ChenBird 2 1.680 PSO 2 ChenBird 2 0.508 RandomSearch1 3 Schwefel2d26N6 19 0.437 PSO 2 Schwefel2d23N6 18 0.465 PSO 2 RosenbrockRotatedN6 14 1.058 RandomSearch1 3 Schwefel2d21N6 17 0.350 Some initial visualizations in terms of box-plots p1&lt;-ggplot(d) + geom_boxplot(aes(x=Algorithm, y=y))+ labs(y=&quot;Time to complete x10,000&quot;) p1 + plot_annotation(title =&quot;Box-plot of the time per evaluation&quot;) lmfit &lt;- lm(y~Algorithm, data=d) p2&lt;-ggplot()+ geom_qq(aes(sample=lmfit$residuals))+ geom_qq_line(aes(sample=lmfit$residuals))+ labs(x=&quot;Standard normal quantiles&quot;, y=&quot;Sample quantiles&quot;) p2 + plot_annotation(title = &quot;Q-Q plot for normality analysis&quot;) 6.2 Stan model The Stan model is specified in the file: './stanmodels/multiplegroups.stan' print_stan_code(&#39;./stanmodels/multiplegroups.stan&#39;) // Multiple group comparison // Author: David Issa Mattos // Date: 23 June 2020 // // data { int &lt;lower=1&gt; N_total; // Sample size real y[N_total]; // time to complete variable //To model each algorithm independently int &lt;lower=1&gt; N_algorithm; // Number of algorithms int algorithm_id[N_total]; //vector that has the id of each algorithm //To model the influence of each benchmark int &lt;lower=1&gt; N_bm; int bm_id[N_total]; } parameters { //Fixed effect real a_alg[N_algorithm];//the mean effect given by the algorithms real &lt;lower=0&gt; sigma[N_algorithm];//std for the student t // //Random effect. The effect of the benchmarks real a_bm_norm[N_bm];//the mean effect given by the base class type real&lt;lower=0&gt; s;//std for the random effects real&lt;lower=0&gt; nu;//std for the random effects } model { real mu[N_total]; real sigma_i[N_total]; sigma ~ exponential(1); nu ~ exponential(1.0/30.0); //Fixed effect a_alg ~ normal(0,1); // //Random effects s ~ exponential(1); a_bm_norm ~ normal(0,1); for (i in 1:N_total) { mu[i] = a_alg[algorithm_id[i]] + a_bm_norm[bm_id[i]]*s; sigma_i[i] = sigma[algorithm_id[i]]; } y ~ student_t(nu, mu, sigma_i); } Let’s compile and start sampling with the Stan function. In the data folder you can find the specific data used to fit the model after all transformations \"./data/multiplegroup-data.RDS\" standata &lt;- list( N_total=nrow(d), y = d$y, N_algorithm = length(algorithms), algorithm_id = d$AlgorithmID, N_bm = length(bm), bm_id = d$CostFunctionID ) saveRDS(standata, file = &quot;./data/multiplegroups-data.RDS&quot;) For computation time sake we are not running this chunk every time we compile this document. From now on we will load from the saved Stan fit object. However, when we change our model or the data we can just run this chunk separately. Here we increased the maxtreedepth and the number of iterations so we have a higher effective sample for inference. Both of these do not impact the validity of the chain just the computation efficiency. standata&lt;-readRDS(&quot;./data/multiplegroups-data.RDS&quot;) multiplegroup_fit &lt;- stan(file = &#39;./stanmodels/multiplegroups.stan&#39;, data=standata, chains = 4, warmup = 400, iter = 4000, # include = T, # sample_file = &quot;./stanmodels/multiplegroups.csv&quot; control = list(max_treedepth = 15)) saveRDS(multiplegroup_fit, file = &quot;./data/multiplegroups-fit.RDS&quot;) 6.3 Diagnosis a_alg_v &lt;- c(&quot;a_alg[1]&quot;, &quot;a_alg[2]&quot;, &quot;a_alg[3]&quot;) sigma_v &lt;- c(&quot;sigma[1]&quot;, &quot;sigma[2]&quot;, &quot;sigma[3]&quot;) rstan::traceplot(multiplegroup_fit, pars=a_alg_v) rstan::traceplot(multiplegroup_fit, pars=sigma_v) rstan::traceplot(multiplegroup_fit, pars=c(&#39;s&#39;, &#39;nu&#39;)) Another diagnosis is to look at the Rhat. If Rhat is greater than 1.05 it indicates a divergence in the chains (they did not mix well). The table below shows a summary of the sampling. kable(summary(multiplegroup_fit)$summary, &quot;html&quot;,) %&gt;% kable_styling(bootstrap_options = c(&#39;striped&#39;,&quot;hover&quot;, &quot;condensed&quot; )) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat a_alg[1] 1.7815819 0.0024748 0.0566810 1.6721093 1.7445310 1.7807935 1.8199106 1.8926830 524.5383 1.002721 a_alg[2] 0.5696040 0.0024743 0.0566789 0.4603005 0.5326239 0.5687407 0.6077809 0.6804053 524.7432 1.002723 a_alg[3] 0.4428074 0.0024754 0.0566494 0.3332348 0.4059292 0.4419022 0.4810402 0.5535471 523.7002 1.002756 sigma[1] 0.0876911 0.0000311 0.0017075 0.0844449 0.0865150 0.0876638 0.0888157 0.0911495 3013.0294 1.001474 sigma[2] 0.0694382 0.0000276 0.0014904 0.0665632 0.0684023 0.0693989 0.0704513 0.0724145 2913.9665 1.001041 sigma[3] 0.0368466 0.0000150 0.0008085 0.0352774 0.0363041 0.0368220 0.0373747 0.0384569 2897.1475 1.000519 a_bm_norm[1] 0.7192083 0.0086246 0.2094808 0.3161019 0.5779758 0.7220803 0.8677116 1.1162210 589.9497 1.003545 a_bm_norm[2] -0.1814373 0.0079796 0.1837739 -0.5391235 -0.3097406 -0.1810262 -0.0580464 0.1761930 530.4046 1.003210 a_bm_norm[3] -0.5827379 0.0083120 0.1959346 -0.9565364 -0.7190948 -0.5808377 -0.4482490 -0.2036032 555.6618 1.004407 a_bm_norm[4] -0.6089228 0.0083542 0.1970467 -0.9822168 -0.7462298 -0.6064975 -0.4755324 -0.2258659 556.3242 1.004509 a_bm_norm[5] -0.2476612 0.0080067 0.1849829 -0.6059732 -0.3757603 -0.2457094 -0.1225043 0.1104547 533.7774 1.003279 a_bm_norm[6] 0.4750596 0.0082505 0.1959683 0.0961207 0.3410841 0.4779159 0.6141989 0.8520264 564.1714 1.002989 a_bm_norm[7] -0.6420408 0.0083861 0.1987948 -1.0201032 -0.7794661 -0.6404438 -0.5074182 -0.2562647 561.9448 1.004617 a_bm_norm[8] -0.1634319 0.0079914 0.1838506 -0.5206348 -0.2915316 -0.1620165 -0.0398618 0.1912232 529.2798 1.003135 a_bm_norm[9] 2.1154599 0.0123913 0.3386954 1.4588894 1.8888847 2.1236694 2.3444388 2.7697322 747.1082 1.006364 a_bm_norm[10] -0.1804465 0.0079840 0.1839089 -0.5387432 -0.3089380 -0.1785651 -0.0566686 0.1739718 530.6024 1.003236 a_bm_norm[11] 0.9041127 0.0089536 0.2222174 0.4740013 0.7546731 0.9095963 1.0585790 1.3270507 615.9702 1.004018 a_bm_norm[12] -0.7819305 0.0086115 0.2067054 -1.1711710 -0.9250797 -0.7817243 -0.6403822 -0.3839085 576.1671 1.005135 a_bm_norm[13] -0.6772704 0.0084572 0.2008767 -1.0568907 -0.8167815 -0.6756358 -0.5401214 -0.2884239 564.1649 1.004795 a_bm_norm[14] 1.7172228 0.0110972 0.2962334 1.1467413 1.5179348 1.7242375 1.9183202 2.2869387 712.5936 1.005705 a_bm_norm[15] -0.2509447 0.0080060 0.1849612 -0.6096211 -0.3798723 -0.2493476 -0.1265618 0.1081399 533.7393 1.003362 a_bm_norm[16] -0.6887018 0.0084737 0.2014353 -1.0669924 -0.8280677 -0.6876355 -0.5517005 -0.2998266 565.0964 1.004953 a_bm_norm[17] -0.2987615 0.0080353 0.1858974 -0.6575569 -0.4267789 -0.2965663 -0.1724545 0.0592583 535.2275 1.003464 a_bm_norm[18] -0.2057157 0.0079888 0.1842716 -0.5629628 -0.3336642 -0.2054677 -0.0819283 0.1508168 532.0458 1.003351 a_bm_norm[19] -0.1772225 0.0079777 0.1838359 -0.5353252 -0.3051236 -0.1764972 -0.0539611 0.1780432 531.0154 1.003200 a_bm_norm[20] 0.0021975 0.0079578 0.1833495 -0.3579432 -0.1252151 0.0040986 0.1274310 0.3529663 530.8547 1.002951 a_bm_norm[21] -0.0370757 0.0079567 0.1833234 -0.3970028 -0.1650148 -0.0351024 0.0858728 0.3142432 530.8508 1.002966 a_bm_norm[22] -0.2582016 0.0080267 0.1850542 -0.6155364 -0.3865295 -0.2570828 -0.1331500 0.0991284 531.5186 1.003413 a_bm_norm[23] -0.7357537 0.0085331 0.2038511 -1.1186036 -0.8766281 -0.7351464 -0.5982257 -0.3425063 570.7101 1.004962 a_bm_norm[24] -0.8252724 0.0086947 0.2094949 -1.2189848 -0.9708733 -0.8254469 -0.6819852 -0.4221552 580.5534 1.005230 a_bm_norm[25] -0.3359663 0.0080697 0.1868876 -0.6971104 -0.4646943 -0.3327841 -0.2091031 0.0259680 536.3423 1.003643 a_bm_norm[26] 0.3504413 0.0081328 0.1907707 -0.0194125 0.2175444 0.3538897 0.4859020 0.7197615 550.2295 1.002923 a_bm_norm[27] -0.7344475 0.0085396 0.2039208 -1.1172730 -0.8755600 -0.7335636 -0.5964523 -0.3408633 570.2296 1.004995 a_bm_norm[28] 3.7056060 0.0184140 0.5268846 2.6654739 3.3494149 3.7062854 4.0644549 4.7388580 818.7208 1.007627 a_bm_norm[29] -0.4139099 0.0081410 0.1892188 -0.7771179 -0.5447576 -0.4105746 -0.2855314 -0.0474645 540.2168 1.003952 a_bm_norm[30] -0.1763685 0.0079847 0.1837990 -0.5350264 -0.3048733 -0.1757948 -0.0531583 0.1779765 529.8757 1.003222 s 0.3064198 0.0014329 0.0423732 0.2379312 0.2766066 0.3013470 0.3301371 0.4061672 874.5406 1.009378 nu 2.7520111 0.0015060 0.0796144 2.5992295 2.6986152 2.7495934 2.8046633 2.9117775 2794.5987 1.001687 lp__ 14070.3651083 0.1502401 5.7707953 14058.1445159 14066.7032470 14070.6873137 14074.3315285 14080.8165057 1475.3660 1.004358 6.4 Results and Plots First lets get the HPDI of every parameter. Then we restrict to the algorithms, them to the slopes, then to the parameter s hpdi &lt;- get_HPDI_from_stanfit(multiplegroup_fit) hpdi_algorithm &lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;a_alg\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_sigma&lt;- hpdi %&gt;% dplyr::filter(str_detect(Parameter, &quot;sigma\\\\[&quot;)) %&gt;% dplyr::mutate(Parameter=algorithms) #Changing to the algorithms labels hpdi_s &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;s&#39;) hpdi_nu &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;nu&#39;) hpdi_nu_s &lt;- hpdi %&gt;% dplyr::filter(Parameter==&#39;nu&#39; | Parameter==&#39;s&#39;) p_alg&lt;-ggplot(data=hpdi_algorithm, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;a_alg&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_alg + plot_annotation(title = &#39;HPDI interval for the algorithms&#39;) p_sigma&lt;-ggplot(data=hpdi_sigma, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;sigma&quot;, x=&quot;Algorithm&quot;)+ coord_flip() p_sigma + plot_annotation(title = &#39;HPDI interval for sigma&#39;) p_s &lt;- ggplot(data=hpdi_s, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;s&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_s + plot_annotation(title = &#39;HPDI interval std of the benchmarks&#39;) p_nu &lt;- ggplot(data=hpdi_nu, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;nu&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_nu + plot_annotation(title = &#39;HPDI interval of the degree of freedom&#39;) p_nu_s &lt;- ggplot(data=hpdi_nu_s, aes(x=Parameter))+ geom_pointrange(aes( ymin=HPDI.lower, ymax=HPDI.higher, y=Mean))+ labs(y=&quot;Estimate&quot;, x=&quot;Parameter&quot;)+ coord_flip() p_nu_s + plot_annotation(title = &#39;HPDI interval&#39;) Now lets get a posterior distribution of the difference posterior &lt;- rstan::extract(multiplegroup_fit) a_alg &lt;- as_tibble(posterior$a_alg) colnames(a_alg) &lt;- algorithms sample_a_alg &lt;- dplyr::sample_n(a_alg, size=1000, replace=T) %&gt;% dplyr::mutate(PSO_Random = PSO-RandomSearch1, DE_PSO= DifferentialEvolution-PSO, DE_Random = DifferentialEvolution-RandomSearch1) %&gt;% dplyr::select(-DifferentialEvolution,-PSO,-RandomSearch1) #Getting HPDI from a data frame and creating a table instead of plotting... hpdi_diff&lt;-HDInterval::hdi(sample_a_alg,credMass=0.95) hpdi_diff&lt;-hpdi_diff %&gt;% as_tibble(rownames = &quot;Metric&quot;) %&gt;% tibble::add_row(Metric=&quot;Mean&quot;, PSO_Random=mean(sample_a_alg$PSO_Random), DE_PSO=mean(sample_a_alg$DE_PSO), DE_Random=mean(sample_a_alg$DE_Random)) %&gt;% tidyr::pivot_longer(cols=-Metric, names_to=&quot;AlgorithmDifference&quot;, values_to=&#39;values&#39;) %&gt;% tidyr::pivot_wider(names_from =Metric , values_from=values) %&gt;% dplyr::mutate(Difference=c(&#39;PSO - RandomSearch&#39;, &#39;DifferentialEvolution - PSO&#39;, &#39;DifferentialEvolution - RandomSearch&#39;)) %&gt;% dplyr::select(Difference, Lower=lower, Mean, Upper=upper) kable(hpdi_diff, booktabs=T, format.args = list(scientific = FALSE), digits = 3) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;)) Difference Lower Mean Upper PSO - RandomSearch 0.123 0.127 0.130 DifferentialEvolution - PSO 1.207 1.212 1.218 DifferentialEvolution - RandomSearch 1.334 1.339 1.343 Creating an output table rename_pars &lt;- c( paste(rep(&#39;a_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;), paste(rep(&#39;sigma_&#39;,length(algorithms)),algorithms, sep = &quot;&quot;), &#39;s&#39;, &#39;nu&#39;) t&lt;-create_table_model(multiplegroup_fit, pars=c(a_alg_v, sigma_v, &#39;s&#39;,&#39;nu&#39;),rename_pars) saveRDS(t,&#39;./statscomp-paper/tables/datafortables/multiplegroupsdifference-par-table.RDS&#39;) "],
["sensitivity-analysis-and-model-comparison.html", "Chapter 7 Sensitivity analysis and model comparison", " Chapter 7 Sensitivity analysis and model comparison "]
]
